{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.0\n",
      "Dispositivos: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPUs (tipo GPU): [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Dispositivos:\", tf.config.list_physical_devices())\n",
    "print(\"GPUs (tipo GPU):\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "As a baseline model, we implement the reference architecture provided in the challenge description:  \n",
    "a **3-layer 1D Convolutional Neural Network** consisting of:\n",
    "\n",
    "- Two convolution + max-pool blocks (each pooling with factor 10),\n",
    "- One final convolution layer producing a 1 Hz probability sequence (90 values per window).\n",
    "\n",
    "This baseline is appropriate because:\n",
    "\n",
    "1. It is the *official benchmark model* of the challenge.  \n",
    "2. It directly processes raw PSG data at 100 Hz without handcrafted features.  \n",
    "3. It produces a segmentation mask at 1 Hz that aligns with the provided ground-truth labels.  \n",
    "4. It provides a fair starting point for assessing more advanced models later.\n",
    "\n",
    "This model does not incorporate temporal recurrence or attention; it is intentionally simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Each training example contains:\n",
    "\n",
    "- **8 PSG channels**, sampled at **100 Hz**, giving a tensor of shape `(9000, 8)` for each 90-second window.\n",
    "- **A segmentation mask** of shape `(90,)`, sampled at 1 Hz.\n",
    "\n",
    "For this baseline, we directly feed the raw 8-channel signals to the CNN.  \n",
    "No feature engineering is performed.\n",
    "\n",
    "The subject identity for each window is provided separately in the file\n",
    "`X_train_h7ipJUo.csv`, which is used only to perform a **subject-wise train/validation split**\n",
    "to avoid data leakage between train and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4400, 9000, 8)\n"
     ]
    }
   ],
   "source": [
    "#load X from H5 file\n",
    "input_path = r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\00_pre files\\X_normalized.h5\"\n",
    "with h5py.File(input_path, \"r\") as f:\n",
    "    X = f[\"data\"][:]  # Load the dataset into a NumPy array\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "\n",
    "# print shape of X\n",
    "print(\"X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  Subject_ID\n",
      "0  0.0         0.0\n",
      "1  1.0         0.0\n",
      "2  2.0         0.0\n",
      "3  3.0         0.0\n",
      "4  4.0         0.0\n",
      "y shape: (4400, 90)\n",
      "Subjects shape: (4400,)\n"
     ]
    }
   ],
   "source": [
    "# Load subject metadata\n",
    "meta = pd.read_csv(r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\00_pre files\\X_train_h7ipJUo.csv\")    # contains subject IDs\n",
    "print(meta.head())\n",
    "\n",
    "subject_ids = meta[\"Subject_ID\"].to_numpy()\n",
    "\n",
    "# Load y CSV file\n",
    "y_path = r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\00_pre files\\y_train_tX9Br0C.csv\"\n",
    "\n",
    "\n",
    "y_df = pd.read_csv(y_path)\n",
    "\n",
    "# Save ID separately if needed for alignment or merging\n",
    "y_id = y_df[\"ID\"].to_numpy()\n",
    "\n",
    "# Keep only mask columns\n",
    "mask_cols = [c for c in y_df.columns if c.startswith(\"y_\")]\n",
    "\n",
    "y = y_df[mask_cols].to_numpy()\n",
    "# Convert y to float32\n",
    "y = y.astype(\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Subjects shape:\", subject_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtype: float32\n",
      "y dtype: float32\n",
      "subject_ids dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# data types\n",
    "#X = X.astype(\"float32\")\n",
    "#y = y.astype(\"float32\")\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n",
    "print(\"subject_ids dtype:\", subject_ids.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject-wise Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (3000, 9000, 8)\n",
      "Val windows: (1400, 9000, 8)\n",
      "Train subjects: [17. 10. 16. 21. 12. 15.  7.  6.  9.  3.  0. 18.  5. 11. 14.]\n",
      "Number of train subjects: 15\n",
      "Validation subjects: [ 1.  2.  4.  8. 13. 19. 20.]\n"
     ]
    }
   ],
   "source": [
    "def train_val_split_by_subject(X, y, subject_ids, train_ratio=0.7, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    unique_subj = np.unique(subject_ids)\n",
    "    rng.shuffle(unique_subj)\n",
    "\n",
    "    n_train = int(len(unique_subj) * train_ratio)\n",
    "    train_subj = unique_subj[:n_train]\n",
    "\n",
    "    train_mask = np.isin(subject_ids, train_subj)\n",
    "    val_mask   = ~train_mask\n",
    "\n",
    "    return X[train_mask], X[val_mask], y[train_mask], y[val_mask], train_subj\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val, train_subjects = train_val_split_by_subject(\n",
    "    X, y, subject_ids, train_ratio=0.7, seed=42\n",
    ")\n",
    "\n",
    "print(\"Train windows:\", X_train.shape)\n",
    "print(\"Val windows:\", X_val.shape)\n",
    "print(\"Train subjects:\", train_subjects)\n",
    "print(\"Number of train subjects:\", len(train_subjects))\n",
    "print(\"Validation subjects:\", np.unique(subject_ids[~np.isin(subject_ids, train_subjects)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: float32\n",
      "y_train dtype: float32\n",
      "X_val dtype: float32\n",
      "y_val dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# types\n",
    "\n",
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "print(\"X_val dtype:\", X_val.dtype)\n",
    "print(\"y_val dtype:\", y_val.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Below we implement the 3-layer CNN baseline as specified by the challenge.\n",
    "Two Conv1D + MaxPool1D blocks downsample the 100 Hz signal to 1 Hz, and the final\n",
    "Conv1D layer outputs class probabilities for each of the 90 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 9000, 32)          6432      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 900, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 900, 64)           51264     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 90, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 90, 1)             193       \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 90)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,889\n",
      "Trainable params: 57,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FS = 100\n",
    "WINDOW_SECONDS = 90\n",
    "N_SAMPLES = FS * WINDOW_SECONDS  # 9000\n",
    "N_CHANNELS = 8\n",
    "\n",
    "def build_baseline_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(N_SAMPLES, N_CHANNELS)),\n",
    "\n",
    "        layers.Conv1D(32, kernel_size=25, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=10),  # 9000 → 900\n",
    "\n",
    "        layers.Conv1D(64, kernel_size=25, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=10),  # 900 → 90\n",
    "\n",
    "        layers.Conv1D(1, kernel_size=3, padding='same', activation='sigmoid'),\n",
    "        layers.Lambda(lambda t: tf.squeeze(t, axis=-1))  # (batch, 90)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_baseline_cnn()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive class weight: 13.551333130451082\n"
     ]
    }
   ],
   "source": [
    "positive_ratio = np.mean(y)     # % of 1s\n",
    "neg_ratio = 1 - positive_ratio\n",
    "\n",
    "pos_weight = neg_ratio / positive_ratio\n",
    "print(\"Positive class weight:\", pos_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce(pos_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight = 1 + (pos_weight - 1) * y_true\n",
    "        return K.mean(bce * weight)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    metrics=['accuracy'],\n",
    "    loss=weighted_bce(pos_weight=pos_weight)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"C:\\\\Users\\\\giuli\\\\Documents\\\\Open_Campus\\\\Sleep_Apnea\\\\2_BaselineModel\\\\baseline_lr1e-6.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1\n",
    "    ),\n",
    "    #tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    #monitor='val_loss',\n",
    "    #factor=0.3,       # divide LR por 2 quando não melhora\n",
    "    #patience=3,       # espera 3 epochs sem melhora\n",
    "    #min_lr=1e-6\n",
    "    #)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2296 - accuracy: 0.0023\n",
      "Epoch 1: val_loss improved from inf to 1.43337, saving model to C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\2_BaselineModel\\baseline_lr1e-6.keras\n",
      "94/94 [==============================] - 14s 147ms/step - loss: 1.2296 - accuracy: 0.0023 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2296 - accuracy: 0.0020\n",
      "Epoch 2: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 133ms/step - loss: 1.2296 - accuracy: 0.0020 - val_loss: 1.4335 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0023\n",
      "Epoch 3: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.2295 - accuracy: 0.0023 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0020\n",
      "Epoch 4: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.2295 - accuracy: 0.0020 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0027\n",
      "Epoch 5: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 14s 145ms/step - loss: 1.2295 - accuracy: 0.0027 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0023\n",
      "Epoch 6: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 137ms/step - loss: 1.2295 - accuracy: 0.0023 - val_loss: 1.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0020\n",
      "Epoch 7: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 14s 149ms/step - loss: 1.2295 - accuracy: 0.0020 - val_loss: 1.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0020\n",
      "Epoch 8: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 142ms/step - loss: 1.2295 - accuracy: 0.0020 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0020\n",
      "Epoch 9: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 134ms/step - loss: 1.2295 - accuracy: 0.0020 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.0023\n",
      "Epoch 10: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 142ms/step - loss: 1.2295 - accuracy: 0.0023 - val_loss: 1.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - ETA: 0s - loss: 1.2294 - accuracy: 0.0020Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.43337\n",
      "94/94 [==============================] - 13s 138ms/step - loss: 1.2294 - accuracy: 0.0020 - val_loss: 1.4340 - val_accuracy: 0.0000e+00\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "baseline = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "To establish a simple numerical baseline, we evaluate the model at the *window level* by\n",
    "thresholding the predicted 1-Hz mask and assessing standard binary classification metrics:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "\n",
    "For this baseline notebook, we evaluate whether the window contains at least one apnea event.\n",
    "The official challenge evaluation (event-level F1 with IoU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 48ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_apnea       0.82      0.93      0.87      1078\n",
      "       apnea       0.58      0.34      0.43       322\n",
      "\n",
      "    accuracy                           0.79      1400\n",
      "   macro avg       0.70      0.63      0.65      1400\n",
      "weighted avg       0.77      0.79      0.77      1400\n",
      "\n",
      "Confusion matrix:\n",
      "[[999  79]\n",
      " [213 109]]\n"
     ]
    }
   ],
   "source": [
    "# Convert 90-second masks into a binary window label: apnea yes/no\n",
    "y_true_window = (y_val.max(axis=1) > 0).astype(int)\n",
    "\n",
    "# Predict mask\n",
    "y_pred_mask = model.predict(X_val)\n",
    "y_pred_window = (y_pred_mask.max(axis=1) > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_true_window, y_pred_window, target_names=[\"no_apnea\", \"apnea\"]))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true_window, y_pred_window))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAID9JREFUeJzt3QuwVdV9P/Df4Y0koGgEGUDUoPjEB8igZizFlBDLhDiJUUlLNKbp/w/RlqFTTCqY2Ii2FEkiY0oyE8c2GvvwEtM2pEr8ixiNQSFNG7ViyGBAJMbKywaUe/6ztt7LvZdzn9zH4vD5zGzO2c+zzr6bs79nrbX3KZXL5XIAAGSsV08XAACgNQILAJA9gQUAyJ7AAgBkT2ABALInsAAA2RNYAIDsCSwAQPb6RBWora2NrVu3xnvf+94olUo9XRwAoA3SvWt37doVI0aMiF69elV/YElhZdSoUT1dDACgA15++eUYOXJk9QeWVLNS94YHDx7c08UBANpg586dRYVD3Xm86gNLXTNQCisCCwAcXtrSnUOnWwAgewILAJA9gQUAyJ7AAgBkT2ABALInsAAA2RNYAIDsCSwAQPYEFgAgewILAJA9gQUAyJ7AAgBkryp+/BDoAeXyu0Ptu8P+Bs/fHWqbjB+0bLnJ8k23UTd//4HXjHKD58WTxs/btVx08vYaLJeUejUYer/z2KvCtGJ6g+cHTat7LFWY1o512/ADc4elRsfZ/maOpabHWINj8KBpdcuVK0zrjHXrjp0Kj0nFedHCtCbzOrSNptMqbKNXn4hpX46eIrC0ZP9bEY/e9u4frMGHZ9JovNzCeN0fvB3Lt7pMW8tQ6eCte3MtHdxN5leadqjbrDi/C3XpB3Wpwmt01bROet02h4omgaLhB2/DEzOHh2aDUunAtEKFcFZxvOHG27pOJ4/TfXr3F1iylT6U1y7t6VJAFWhYM9C0hqHUQu1Ag3mNglfTENbeedG29Spuo43zGn5ZafRt/90geNC0pgGy0jf2ZmoQ2nryrl/+7TjylDpQc9UVNWENj+m6cr17/B10HDadF+8+r3ssHcI2mk6rsHzTaamGpQepYWlJOtAm/Z8m1al1B9u7j82Ov/ttpk3Llw7+YG5xnWjbNg868KL5g7YYLbVjftNp0Qnb7CJdWoPT9FtfpWlNq1jbul7DadGJ2yo3+dBt8O26tdBQcbmmIaTpclXcFJGLhjVhlYJQpSaTSs0mabylINbieAMd3kZHx9vSXOYYPNwJLC3p3Sdi+u3d9scA6JC60Bm9I3r3tROpSq4SAgCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAVF9gWbNmTcyYMSNGjBgRpVIpVq5c2eZ1n3jiiejTp0+ce+65B81bvnx5jBkzJgYMGBCTJk2Kp59+ur1FAwCqVLsDy549e2L8+PFFwGiPN954I/7wD/8wpk6detC8Bx54IObNmxeLFi2KZ599ttj+tGnTYvv27e0tHgBQhUrlcrnc4ZVLpaipqYmZM2e2uuxVV10VY8eOjd69exe1Mhs2bKifl2pUJk6cGHfddVcxXltbG6NGjYrPfe5zsWDBgla3vXPnzhgyZEjs2LEjBg8e3NG3AwB0o/acv7ulD8u3vvWt+MUvflHUoDS1b9++eOaZZ+Kyyy47UKhevYrxJ598suL29u7dW7zJhgMAUL26PLC8+OKLRS3J3//93xf9V5p67bXXYv/+/TFs2LBG09P4tm3bKm5z8eLFRSKrG1JtDABQvbo0sKQgcs0118QXv/jFOPXUUzttuzfddFNRfVQ3vPzyy522bQAgPwdXeXSiXbt2xbp162L9+vUxd+7c+v4pqdtMqm3593//97jkkkuKfi2vvvpqo3XT+PDhwytut3///sUAABwZurSGJXWg+dnPflZ0sK0b/viP/zhOO+204nnqbNuvX7+44IILYvXq1fXrpVCTxidPntyVxQMAqrWGZffu3bFx48b68U2bNhXhY+jQoTF69OiiuWbLli1x7733Fp1nzzrrrEbrH3/88cW9VhpOT5c0z549OyZMmBAXXnhhLFu2rLh8+tprrz3U9wcAHImBJTXxTJkypVHYSFLguOeee+KVV16JzZs3t2ubn/jEJ+LXv/51LFy4sOhom24st2rVqoM64gIAR6ZDug9LLtyHBQAOP9ndhwUA4FAILABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAqi+wrFmzJmbMmBEjRoyIUqkUK1eubHH5tWvXxsUXXxzHHntsDBw4MMaNGxd33nlno2VuueWWYlsNh7QcAEDSp727Yc+ePTF+/Pi47rrr4oorrmh1+UGDBsXcuXPjnHPOKZ6nAPPZz362eP5Hf/RH9cudeeaZ8cgjj9SP9+nT7qIBAFWq3alg+vTpxdBW5513XjHUGTNmTDz44IPx+OOPNwosKaAMHz68vcUBAI4A3d6HZf369fGjH/0oLr300kbTX3zxxaKZ6eSTT45Zs2bF5s2bm93G3r17Y+fOnY0GAKB6dVtgGTlyZPTv3z8mTJgQc+bMieuvv75+3qRJk+Kee+6JVatWxd133x2bNm2KD3zgA7Fr166K21q8eHEMGTKkfhg1alR3vQ0AoAeUyuVyucMrl0pRU1MTM2fObHXZFEJ2794dTz31VCxYsCDuuuuuuPrqqysu+8Ybb8SJJ54YS5cujU9/+tMVa1jSUCfVsKTQsmPHjhg8eHBH3w4A0I3S+TtVPLTl/N1tPVtPOumk4vHss8+OV199tbgyqLnAcvTRR8epp54aGzdurDg/1dSkAQA4MvTIfVhqa2sb1ZA0lWpiXnrppTjhhBO6tVwAQJ7aXcOSwkTDmo/U1LNhw4YYOnRojB49Om666abYsmVL3HvvvcX85cuXF9Pr7quS7uOyZMmSuOGGG+q3MX/+/OLeLqkZaOvWrbFo0aLo3bt3szUwAMCRpd2BZd26dTFlypT68Xnz5hWPs2fPLjrOvvLKK42u8Em1KSnEpGCTLl0+5ZRT4o477ijuxVLnV7/6VRFOfvOb38T73ve+uOSSS4q+Luk5AMAhdbo9HDvtAEB77d+/P9566y07rgP69u1btJocNp1uAeBwk77Tb9u2rbh6lY5LF9Okm8Omq4s7SmABgGbUhZXjjz8+jjrqqEM64R6pge/NN9+M7du3F+OHcjGNwAIAzTQD1YWV9AO+dEz64eMkhZa0L5trHsrysmYAyF1dn5VUs8KhqduHh9IPSGABgBZoBspjHwosAED2BBYAoFljxoyJZcuWRU/T6RYAqszv/M7vxLnnntspQeMnP/lJDBo0KHqawAIAR+Dlxvv37y/uQN+aXO46r0kIAKrIpz71qXjsscfiK1/5StHZNQ3pp3PS4/e///244IILon///rF27drih4Y/8pGPxLBhw+I973lPTJw4MR555JEWm4TSdr75zW/GRz/60eLqn7Fjx8ZDDz3U5e9LYAGA9twIbd/b3T6U2/ErOimoTJ48OT7zmc8Uv++XhlGjRhXzFixYELfffns899xzcc455xQ/aPzhD384Vq9eHevXr48PfehDxY8RN/xNwEq++MUvxpVXXhn/8R//Uaw/a9aseP3117v0ONIkBABt9L9v7Y8zFv6g2/fXz780LY7q17ZTdvptnn79+hW1H+l2+Mnzzz9fPH7pS1+KD37wg/XLDh06NMaPH18/fuutt0ZNTU1RYzJ37twWa3HSjxYnt912W3z1q1+Np59+ugg8XUUNCwAcISZMmNBoPNWwzJ8/P04//fTi935Ss1CqfWmthiXVztRJHXLTDxfW3X6/q6hhAYA2Gti3d1Hb0ROv2xmaXu2TwsrDDz8cS5Ysife///3FbfQ/9rGPxb59+1r9BeaGUr+W2tra6EoCCwC0UToxt7Vppif169evuAqoNU888UTRvJM60NbVuPzyl7+MHGkSAoAqM2bMmPjxj39chI/XXnut2dqPdIXPgw8+GBs2bIif/vSncc0113R5TUlHCSwAUGXmz59f/CryGWecUdxHpbk+KUuXLo1jjjkmLrroouLqoGnTpsX5558fOSqV23OtVKZ27txZ9IresWNH0fEHAA7Vb3/729i0aVOcdNJJMWDAADu0C/Zle87falgAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLADAQb9FtGzZssiJwAIAZE9gAQCyJ7AAQBVZsWJFjBgxImpraxtN/8hHPhLXXXddvPTSS8XzYcOGxXve856YOHFiPPLII5E7gQUA2qpcjti3p/uHcrnNRfz4xz8ev/nNb+LRRx+tn/b666/HqlWrYtasWbF79+748Ic/HKtXr47169fHhz70oZgxY0Zs3rw56+OgT08XAAAOG2+9GXHbiO5/3c9vjeg3qE2LHnPMMTF9+vS47777YurUqcW0f/qnf4rjjjsupkyZEr169Yrx48fXL3/rrbdGTU1NPPTQQzF37tzIlRoWAKgys2bNin/+53+OvXv3FuPf/va346qrrirCSqphmT9/fpx++ulx9NFHF81Czz33nBoWAKgafY96p7ajJ163HVITT7lcjn/9138t+qg8/vjjceeddxbzUlh5+OGHY8mSJfH+978/Bg4cGB/72Mdi3759kTNNQgDQVqVSm5tmetKAAQPiiiuuKGpWNm7cGKeddlqcf/75xbwnnngiPvWpT8VHP/rRYjzVuPzyl7+M3AksAFClzUK///u/H//1X/8Vn/zkJ+unjx07Nh588MGiFqZUKsXNN9980BVFOdKHBQCq0O/+7u/G0KFD44UXXohrrrmmfvrSpUuLjrkXXXRREVqmTZtWX/uSMzUsAFCFevXqFVu3bq142/0f/vCHjabNmTOn0XiOTURqWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIALUh3jKXn96HAAgAV9O3bt3h888037Z9DVLcP6/ZpR7gPCwBU0Lt37+LHAbdv316MH3XUUcWdYWlfzUoKK2kfpn2Z9mlHCSwA0Izhw4cXj3WhhY5JYaVuX3aUwAIAzUg1KieccEIcf/zx8dZbb9lPHZCagQ6lZqWOwAIArUgn3M446dJxOt0CANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwCQPYEFAMiewAIAZE9gAQCyJ7AAANkTWACA7AksAED2BBYAIHsCCwBQfYFlzZo1MWPGjBgxYkSUSqVYuXJli8uvXbs2Lr744jj22GNj4MCBMW7cuLjzzjsPWm758uUxZsyYGDBgQEyaNCmefvrp9hYNAKhS7Q4se/bsifHjxxcBoy0GDRoUc+fOLYLOc889F3/xF39RDCtWrKhf5oEHHoh58+bFokWL4tlnny22P23atNi+fXt7iwcAVKFSuVwud3jlUilqampi5syZ7VrviiuuKILM3/3d3xXjqUZl4sSJcddddxXjtbW1MWrUqPjc5z4XCxYsaHV7O3fujCFDhsSOHTti8ODBHXw3AEB3as/5u9v7sKxfvz5+9KMfxaWXXlqM79u3L5555pm47LLLDhSqV69i/Mknn+zu4gEAGerTXS80cuTI+PWvfx1vv/123HLLLXH99dcX01977bXYv39/DBs2rNHyafz555+vuK29e/cWQ8OEBgBUr26rYXn88cdj3bp18fWvfz2WLVsW999/f4e3tXjx4qIKqW5IzUcAQPXqthqWk046qXg8++yz49VXXy1qWa6++uo47rjjonfv3sW0htL48OHDK27rpptuKjrpNqxhEVoAoHr1yH1YUqfauiadfv36xQUXXBCrV69uND+NT548ueL6/fv3LzrnNBwAgOrV7hqW3bt3x8aNG+vHN23aFBs2bIihQ4fG6NGji9qPLVu2xL333lvMT5c/p+np/itJurx5yZIlccMNN9RvI9WWzJ49OyZMmBAXXnhh0WSULp++9tprO+ddAgBHVmBJ/VCmTJlSP17XNJMCxz333BOvvPJKbN68uVFtSQoxKdj06dMnTjnllLjjjjvis5/9bP0yn/jEJ4oOuQsXLoxt27bFueeeG6tWrTqoIy4AcGQ6pPuw5MJ9WADg8JP1fVgAANpLYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQCovsCyZs2amDFjRowYMSJKpVKsXLmyxeUffPDB+OAHPxjve9/7YvDgwTF58uT4wQ9+0GiZW265pdhWw2HcuHHtfzcAQFVqd2DZs2dPjB8/PpYvX97mgJMCy7/927/FM888E1OmTCkCz/r16xstd+aZZ8Yrr7xSP6xdu7a9RQMAqlSf9q4wffr0YmirZcuWNRq/7bbb4rvf/W5873vfi/POO+9AQfr0ieHDh7e3OADAEaDb+7DU1tbGrl27YujQoY2mv/jii0Uz08knnxyzZs2KzZs3N7uNvXv3xs6dOxsNAED16vbAsmTJkti9e3dceeWV9dMmTZoU99xzT6xatSruvvvu2LRpU3zgAx8ogk0lixcvjiFDhtQPo0aN6sZ3AAB0t1K5XC53eOVSKWpqamLmzJltWv6+++6Lz3zmM0WT0GWXXdbscm+88UaceOKJsXTp0vj0pz9dsYYlDXVSDUsKLTt27Cg69gIA+Uvn71Tx0Jbzd7v7sHTUd77znbj++uvjH//xH1sMK8nRRx8dp556amzcuLHi/P79+xcDAHBk6JYmofvvvz+uvfba4vHyyy9vdfnUZPTSSy/FCSec0B3FAwAy1+4alhQmGtZ8pP4mGzZsKDrRjh49Om666abYsmVL3HvvvfXNQLNnz46vfOUrRV+Vbdu2FdMHDhxYVAMl8+fPLy51Ts1AW7dujUWLFkXv3r3j6quv7rx3CgAcOTUs69atKy5Hrrsked68ecXzhQsXFuPpHioNr/BZsWJFvP322zFnzpyixqRuuPHGG+uX+dWvflWEk9NOO63ojHvsscfGU089VdxsDgDgkDrdHo6ddgCAw+/87beEAIDsCSwAQPYEFgAgewILAJA9gQUAyJ7AAgBkT2ABALInsAAA2RNYAIDsCSwAQPYEFgAgewILAJA9gQUAyJ7AAgBkT2ABALInsAAA2RNYAIDsCSwAQPYEFgAgewILAJA9gQUAyJ7AAgBkT2ABALInsAAA2RNYAIDs9enpAuRs39u1MXXp/yuel6L0zuM7D++OpfG6ZwemRTPLHBiPituM1pZvZr0Dr3vwem0tw8FlPjC/tddvqdytvX40s6065XLl6RHlNi/f3CbKzWy83K5ytE9z77Pisu3ednvXaPs+qZ/f4rqtbPsQXrehSv/nGr71Fv9vVjj2Gk6rtFz9/5EK/xcbzW+lDBXfS0vzWvlztrxux1+3OZ3x/+jAOu17jZZep6PHR8NlG+2PFv7uzW+z5WOktWPt4PfQwrwodWCd5l6nfUdC396l+MLlZ0RPEVhaUI5yvPz6/3bfXwMAMtWvTy+BJVd9e/WKmv97UX3qPxDw33nSMPA3Xabu28BB0+umNH44aP6B8crbi+aWb7Bec2VoWv6WytD09eu30IHXb7bMDbbZXODvyLeR5r6JRDd8E2mL9tQqHLTuIb1w275it+Udt2W/tG07bVio2f9zByY2PdbeedpgfpNjrvG0lperm1hx3QplaMuft9zFx0nj7bRhmSg3//+mnTWE7yzfwrY68BqtvXylfd/cZ9jBy7X+ud7ccge21/5jrbNrK+MQaklbW71Xr87/HGwPNSzR8h/nvNHHdN9fAwCoSKdbACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAslcVv9Zc95PeO3fu7OmiAABtVHferjuPV31g2bVrV/E4atSoni4KANCB8/iQIUNaXKZUbkusyVxtbW1s3bo13vve90apVOr09JeC0MsvvxyDBw/u1G1jP3c3x7N9XW0c04f3fk4RJIWVESNGRK9evaq/hiW9yZEjR3bpa6Q/kMDS9ezn7mE/dx/72n6uJoO74FzYWs1KHZ1uAYDsCSwAQPYEllb0798/Fi1aVDzSdezn7mE/dx/72n6uJv0zOBdWRadbAKC6qWEBALInsAAA2RNYAIDsCSwAQPYEllYsX748xowZEwMGDIhJkybF008/3T1/mSPE4sWLY+LEicVdio8//viYOXNmvPDCCz1drKp3++23F3eF/pM/+ZOeLkrV2bJlS3zyk5+MY489NgYOHBhnn312rFu3rqeLVVX2798fN998c5x00knFPj7llFPi1ltvbdPv0dCyNWvWxIwZM4o7z6bPiJUrVzaan/bxwoUL44QTTij2/WWXXRYvvvhidAeBpQUPPPBAzJs3r7iU69lnn43x48fHtGnTYvv27d3yxzkSPPbYYzFnzpx46qmn4uGHH4633norfu/3fi/27NnT00WrWj/5yU/ib//2b+Occ87p6aJUnf/5n/+Jiy++OPr27Rvf//734+c//3n8zd/8TRxzzDE9XbSqcscdd8Tdd98dd911Vzz33HPF+F/91V/F1772tZ4u2mFvz549xbkufVmvJO3nr371q/H1r389fvzjH8egQYOK8+Jvf/vbri9cuqyZyi688MLynDlz6sf3799fHjFiRHnx4sV2WRfZvn17+opUfuyxx+zjLrBr167y2LFjyw8//HD50ksvLd944432cyf68z//8/Ill1xin3axyy+/vHzdddc1mnbFFVeUZ82aZd93ovRZXFNTUz9eW1tbHj58ePmv//qv66e98cYb5f79+5fvv//+cldTw9KMffv2xTPPPFNUdzX8zaI0/uSTT3Z9kjxC7dixo3gcOnRoTxelKqXarMsvv7zRcU3neeihh2LChAnx8Y9/vGjiPO+88+Ib3/iGXdzJLrrooli9enX893//dzH+05/+NNauXRvTp0+3r7vQpk2bYtu2bY0+P9LvAKXuEt1xXqyKHz/sCq+99lrRTjps2LBG09P4888/32PlqmbpV7dTn4pUpX7WWWf1dHGqzne+852iaTM1CdE1fvGLXxRNFakp+fOf/3yxr2+44Ybo169fzJ49227vJAsWLCh+PXjcuHHRu3fv4rP6y1/+csyaNcs+7kIprCSVzot187qSwEJW3/7/8z//s/imROdKPwl/4403Fv2EUgdyui50pxqW2267rRhPNSzpmE7t/QJL5/mHf/iH+Pa3vx333XdfnHnmmbFhw4biy07qKGo/Vy9NQs047rjjiuT+6quvNpqexocPH94df5sjyty5c+Nf/uVf4tFHH42RI0f2dHGqTmreTJ3Fzz///OjTp08xpA7PqfNcep6+oXLo0pUTZ5xxRqNpp59+emzevNnu7UR/9md/VtSyXHXVVcVVWH/wB38Qf/qnf1pcdUjXqTv39dR5UWBpRqrCveCCC4p20obfntL45MmTu/wPc6RI/bpSWKmpqYkf/vCHxWWKdL6pU6fGz372s+KbaN2QagJSFXp6nsI5hy41Zza9LD/1szjxxBPt3k705ptvFn0KG0rHcPqMpuukz+cUTBqeF1PTXLpaqDvOi5qEWpDaoVP1Yvpgv/DCC2PZsmXFJV/XXnttl/9hjqRmoFSt+93vfre4F0tdO2jqyJWu8adzpH3btF9Quhwx3StEf6HOk77lpw6hqUnoyiuvLO7btGLFimKg86T7hKQ+K6NHjy6ahNavXx9Lly6N6667zm4+RLt3746NGzc26mibvtSkCyHS/k5Nb3/5l38ZY8eOLQJMuh9OaopL99Dqcl1+HdJh7mtf+1p59OjR5X79+hWXOT/11FM9XaSqkg7BSsO3vvWtni5a1XNZc9f43ve+Vz7rrLOKSz3HjRtXXrFiRRe90pFr586dxSX56bN5wIAB5ZNPPrn8hS98obx3796eLtph79FHH634mTx79uz6S5tvvvnm8rBhw4pjfOrUqeUXXnihW8pWSv90fSwCAOg4fVgAgOwJLABA9gQWACB7AgsAkD2BBQDInsACAGRPYAEAsiewAADZE1gAgOwJLABA9gQWACB7AgsAELn7/yhz44jIxvecAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(baseline.history[\"loss\"], label=\"train\")\n",
    "plt.plot(baseline.history[\"val_loss\"], label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 49ms/step\n",
      "Best threshold: 0.5\n",
      "Best window-level F1: 0.42745098039215684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# per-window true labels\n",
    "y_true_window = (y_val.max(axis=1) > 0).astype(int)\n",
    "\n",
    "y_pred_mask = model.predict(X_val)           # (N, 90)\n",
    "window_scores = y_pred_mask.max(axis=1)      # (N,)\n",
    "\n",
    "best_t = None\n",
    "best_f1 = -1\n",
    "\n",
    "for t in np.linspace(0.05, 0.5, 20):\n",
    "    y_pred_window = (window_scores >= t).astype(int)\n",
    "    f1 = f1_score(y_true_window, y_pred_window, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n",
    "print(\"Best window-level F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 57ms/step\n",
      "min: 0.012652578\n",
      "max: 0.7973592\n",
      "mean: 0.47291118\n"
     ]
    }
   ],
   "source": [
    "y_pred_mask = model.predict(X_val)\n",
    "\n",
    "print(\"min:\", y_pred_mask.min())\n",
    "print(\"max:\", y_pred_mask.max())\n",
    "print(\"mean:\", y_pred_mask.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (4400, 9000, 8)\n"
     ]
    }
   ],
   "source": [
    "test_file_path = r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\00_pre files\\X_test_normalized.h5\"\n",
    "\n",
    "with h5py.File(test_file_path, \"r\") as f:\n",
    "    raw = f[\"data\"][:]              \n",
    "\n",
    "# to np array of float32\n",
    "    X_test = raw.astype(\"float32\")\n",
    "\n",
    "# shape of X_test\n",
    "    print(\"X_test shape:\", X_test.shape)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 3s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "baseline = keras.models.load_model(\n",
    "    r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\2_BaselineModel\\baseline_lr1e-6.keras\",\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Agora você pode fazer:\n",
    "y_pred = baseline.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize predictions to CSV with id columns  \n",
    "output_df = pd.DataFrame(y_pred, columns=[f\"y_{i}\" for i in range(y_pred.shape[1])])\n",
    "output_df.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save predictions to CSV with id columns\n",
    "\n",
    "output_df = pd.DataFrame(y_pred, columns=[f\"y_{i}\" for i in range(y_pred.shape[1])])\n",
    "output_df.to_csv(r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\2_BaselineModel\\y_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 IDs:      [4400 4401 4402 4403 4404 4405 4406 4407 4408 4409]\n"
     ]
    }
   ],
   "source": [
    "test_file_path = r\"C:\\Users\\giuli\\Documents\\Open_Campus\\Sleep_Apnea\\00_pre files\\X_test.h5\"\n",
    "\n",
    "with h5py.File(test_file_path, \"r\") as f:\n",
    "    raw = f[\"data\"][:]              # shape: (4400, 72002)\n",
    "\n",
    "# 1) metadata\n",
    "ids      = raw[:, 0].astype(int)    # window ID\n",
    "\n",
    "\n",
    "print(\"First 10 IDs:     \", ids[:10])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# escolha um threshold\n",
    "thr = 0.495\n",
    "df_bin = (output_df >= thr).astype(int)\n",
    "\n",
    "# adiciona ID na primeira coluna\n",
    "df_submission = df_bin.copy()\n",
    "df_submission.insert(0, \"ID\", ids)\n",
    "\n",
    "df_submission.to_csv(\"submission_final.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfamd_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
